{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twits = pd.read_csv('train.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todelete = []\n",
    "# clines = twits.shape[0]\n",
    "# # clean twits\n",
    "# for nline in tqdm(range(clines)):\n",
    "#     line = twits.iloc[nline,2]\n",
    "#     line = line.lower()\n",
    "    \n",
    "#     # remove &xx\n",
    "#     line = re.sub(r'&\\S*', '', line)\n",
    "#     # change all @nicks to @twuser\n",
    "#     line = re.sub(r'@\\S*', '@twuser', line)\n",
    "#     # change all ......... to ...\n",
    "#     line = re.sub(r'\\.+', '.', line)\n",
    "#     # remove -*\n",
    "#     line = re.sub(r'', '', line)\n",
    "#     # change ))))) -> ) и (((( -> (\n",
    "#     line = re.sub(r'\\)+', '\\)', line)\n",
    "#     line = re.sub(r'\\(+', '\\(', line)\n",
    "#     # нафик фигню\n",
    "#     line = re.sub(r'\\\\\\\\[\\(\\)]', '', line)\n",
    "#     line = re.sub(r'(\\S)\\- ', r'\\1 ', line)\n",
    "#     line = re.sub(r'(\\S)\\- ', r'\\1 ', line)\n",
    "#     line = re.sub(r'[^a-z 0-9\\,\\.\\=\\-\\(\\)\\[\\]\\:\\;\\'\\+]', '', line)    \n",
    "#     # убрать ссылки\n",
    "#     line = re.sub(r'http:\\S*', '', line)\n",
    "#     line = re.sub(r'www.\\S*', '', line)\n",
    "#     # убрать много минусов, воскл, вопр знаков\n",
    "#     line = re.sub(r'[\\-]+', '-', line)\n",
    "#     line = re.sub(r'[\\!]+', '!', line)\n",
    "#     line = re.sub(r'[\\?]+', '?', line)\n",
    "#     # заменить 3 и более символов на один\n",
    "#     line = re.sub(r'([\\S])\\1{3,}', r'\\1', line)\n",
    "#     # фигня в начале\n",
    "#     line = re.sub(r'(^[^\\w]+)', '', line)\n",
    "#     # 2 пробела -> один\n",
    "#     line = re.sub(r' +', ' ', line)\n",
    "    \n",
    "# #     line = re.sub(r'', '', line)\n",
    "# #     line = re.sub(r'', '', line)\n",
    "# #     line = re.sub(r'', '', line)\n",
    "# #     line = re.sub(r'', '', line)\n",
    "# #     line = re.sub(r'', '', line)\n",
    "# #     line = re.sub(r'', '', line)\n",
    "    \n",
    "#     line = line.strip()\n",
    "    \n",
    "#     if len(line) > 0:\n",
    "#         twits.iloc[nline,2] = line\n",
    "#     else:\n",
    "#         todelete.append(nline)\n",
    "    \n",
    "# for i in sorted(todelete, reverse = True):\n",
    "#     twits.drop(twits.index[[i]], inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this - 22'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"this р°р»сњс-рѕрµс† 22\"\n",
    "re.sub(r'[^a-z 0-9\\,\\.\\=\\-\\(\\)\\[\\]\\:\\;\\'\\+]', '', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twits.to_csv(\"train_amended.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "twits = pd.read_csv('train_amended.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twits 2 lists\n",
    "clines = twits.shape[0]\n",
    "phrases = []\n",
    "tonality = torch.zeros(clines, dtype=torch.int64).to(dev)\n",
    "\n",
    "\n",
    "for nline in range(clines):\n",
    "    phrases.append(twits.iloc[nline,2])\n",
    "    tonality[nline] = torch.tensor(twits.iloc[nline,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twits.iloc[nline,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 0, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tonality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81544"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(phrases)\n",
    "ALL_WORDS = set(text.strip().split(' '))\n",
    "len(ALL_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twuser', 90495),\n",
       " ('i', 49058),\n",
       " ('the', 29660),\n",
       " ('to', 29399),\n",
       " ('you', 25321),\n",
       " ('a', 22779),\n",
       " ('and', 15983),\n",
       " ('it', 15475),\n",
       " ('my', 13648),\n",
       " ('for', 12456)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(text.split(' '))\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем слова с числом повторений меньше 3\n",
    "todelete = set()\n",
    "for i, n in c.items():\n",
    "    if n < 3:\n",
    "        todelete.add(i)\n",
    "        \n",
    "for i in todelete:\n",
    "    del c[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18549"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99981, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18551"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS_COUNT = len(ALL_WORDS)\n",
    "ALL_WORDS = set([w for w, _ in c.most_common(WORDS_COUNT)])\n",
    "INDEX_TO_WORD = ['<pad>', '<miss>'] + list(ALL_WORDS)\n",
    "len(INDEX_TO_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<miss>',\n",
       " 'lady,',\n",
       " '8.2',\n",
       " 'tho.',\n",
       " \"grandma's\",\n",
       " 'mga',\n",
       " 'random',\n",
       " 'bees',\n",
       " 'photobucket']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_WORD)}\n",
    "INDEX_TO_WORD[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.6710e+03, 9.2790e+03, 1.6399e+04, 1.0434e+04, 9.6190e+03,\n",
       "        1.2468e+04, 7.4240e+03, 6.9450e+03, 9.6540e+03, 5.7970e+03,\n",
       "        3.9990e+03, 2.0730e+03, 1.8900e+02, 2.6000e+01, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([  1.  ,   3.34,   5.68,   8.02,  10.36,  12.7 ,  15.04,  17.38,\n",
       "         19.72,  22.06,  24.4 ,  26.74,  29.08,  31.42,  33.76,  36.1 ,\n",
       "         38.44,  40.78,  43.12,  45.46,  47.8 ,  50.14,  52.48,  54.82,\n",
       "         57.16,  59.5 ,  61.84,  64.18,  66.52,  68.86,  71.2 ,  73.54,\n",
       "         75.88,  78.22,  80.56,  82.9 ,  85.24,  87.58,  89.92,  92.26,\n",
       "         94.6 ,  96.94,  99.28, 101.62, 103.96, 106.3 , 108.64, 110.98,\n",
       "        113.32, 115.66, 118.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# распреление длины слов в строке\n",
    "plt.hist([len(s.split(' ')) for s in phrases], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((len(phrases), MAX_LEN), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99981/99981 [00:13<00:00, 7471.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# готовим матрицу - строка - фраза, столбец - индекс слова в этой позиции\n",
    "for i in tqdm(range(len(phrases))):\n",
    "    for j, w in enumerate(phrases[i].split(' ')):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = WORD_TO_INDEX.get(w, WORD_TO_INDEX['<miss>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6755, 10121, 15689,  3397,  2877,     1, 11993,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99981, 35])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99981"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "split = 0.2\n",
    "clines = X.shape[0]\n",
    "ctrainlines = int( clines * (1-split) )\n",
    "X_train = X[0:ctrainlines].to(dev)\n",
    "X_test = X[ctrainlines:].to(dev)\n",
    "Y_train = tonality[0:ctrainlines].to(dev)\n",
    "Y_test = tonality[ctrainlines:].to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev, batch_size):\n",
    "        super(Network, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.input_size = len(INDEX_TO_WORD)\n",
    "        self.embed_size = 200\n",
    "        self.hidden_size = 128\n",
    "        self.n_layers = 1\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embeddings = torch.nn.Embedding(self.input_size, self.embed_size).to(self.dev)\n",
    "        self.gru = torch.nn.RNN(self.embed_size, self.hidden_size, num_layers = self.n_layers, nonlinearity = 'relu', batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(self.hidden_size*34, 2).to(self.dev)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=2).to(self.dev)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.n_layers*2, batch_size, self.hidden_size)\n",
    "        c0 = torch.zeros(self.n_layers*2, batch_size, self.hidden_size)\n",
    "        return h0, c0        \n",
    "\n",
    "    def forward(self, sentences):\n",
    "        #self.hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, hidden = self.gru(embeds)\n",
    "        gru_out = gru_out.reshape(self.batch_size,1,-1)\n",
    "        #tag_space = self.hidden2tag(gru_out)\n",
    "        gru_out = self.hidden2tag(gru_out)\n",
    "        #gru_out = self.softmax(gru_out)\n",
    "        return gru_out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkGRU(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev, batch_size):\n",
    "        super(NetworkGRU, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.input_size = len(INDEX_TO_WORD)\n",
    "        self.embed_size = 200\n",
    "        self.hidden_size = 128\n",
    "        self.n_layers = 1\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embeddings = torch.nn.Embedding(self.input_size, self.embed_size).to(self.dev)\n",
    "        self.gru = torch.nn.GRU(self.embed_size, self.hidden_size, num_layers = self.n_layers, batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(self.hidden_size*34, 2).to(self.dev)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, hidden = self.gru(embeds)\n",
    "        gru_out = gru_out.reshape(self.batch_size,1,-1)\n",
    "        gru_out = self.hidden2tag(gru_out)\n",
    "        return gru_out, hidden\n",
    "\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev, batch_size):\n",
    "        super(NetworkLSTM, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.input_size = len(INDEX_TO_WORD)\n",
    "        self.embed_size = 200\n",
    "        self.hidden_size = 128\n",
    "        self.n_layers = 1\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embeddings = torch.nn.Embedding(self.input_size, self.embed_size).to(self.dev)\n",
    "        self.gru = torch.nn.LSTM(self.embed_size, self.hidden_size, num_layers = self.n_layers, batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(self.hidden_size*34, 2).to(self.dev)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, hidden = self.gru(embeds)\n",
    "        gru_out = gru_out.reshape(self.batch_size,1,-1)\n",
    "        gru_out = self.hidden2tag(gru_out)\n",
    "        return gru_out, hidden\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18551"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(INDEX_TO_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "model = Network(dev,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGRU = NetworkGRU(dev,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM = NetworkLSTM(dev,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 0.1\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lrate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "criterionGRU = torch.nn.CrossEntropyLoss()\n",
    "optimizerGRU = torch.optim.SGD(modelGRU.parameters(), lr=lrate)\n",
    "\n",
    "criterionLSTM = torch.nn.CrossEntropyLoss()\n",
    "optimizerLSTM = torch.optim.SGD(modelLSTM.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time,GRU,LSTM: 5.761,6.510,7.011, Train loss,GRU,LSTM: 0.497,0.522,0.553, delta RGU,LSTM:-0.026,-0.057\n",
      "Epoch 1. Time,GRU,LSTM: 5.750,6.514,7.014, Train loss,GRU,LSTM: 0.473,0.490,0.518, delta RGU,LSTM:-0.017,-0.045\n",
      "Epoch 2. Time,GRU,LSTM: 5.741,6.515,7.023, Train loss,GRU,LSTM: 0.453,0.459,0.490, delta RGU,LSTM:-0.006,-0.037\n",
      "Epoch 3. Time,GRU,LSTM: 5.751,6.512,7.022, Train loss,GRU,LSTM: 0.436,0.435,0.468, delta RGU,LSTM:0.001,-0.032\n",
      "Epoch 4. Time,GRU,LSTM: 5.738,6.521,7.040, Train loss,GRU,LSTM: 0.419,0.412,0.448, delta RGU,LSTM:0.007,-0.029\n",
      "Epoch 5. Time,GRU,LSTM: 5.747,6.515,7.035, Train loss,GRU,LSTM: 0.403,0.389,0.429, delta RGU,LSTM:0.014,-0.026\n",
      "Epoch 6. Time,GRU,LSTM: 5.761,6.518,7.048, Train loss,GRU,LSTM: 0.392,0.366,0.411, delta RGU,LSTM:0.027,-0.019\n",
      "Epoch 7. Time,GRU,LSTM: 5.746,6.533,7.057, Train loss,GRU,LSTM: 0.372,0.342,0.393, delta RGU,LSTM:0.030,-0.021\n",
      "Epoch 8. Time,GRU,LSTM: 5.751,6.536,7.047, Train loss,GRU,LSTM: 0.359,0.318,0.374, delta RGU,LSTM:0.042,-0.015\n",
      "Epoch 9. Time,GRU,LSTM: 5.743,6.532,7.056, Train loss,GRU,LSTM: 0.343,0.293,0.355, delta RGU,LSTM:0.050,-0.012\n",
      "Epoch 10. Time,GRU,LSTM: 5.754,6.539,7.055, Train loss,GRU,LSTM: 0.327,0.268,0.335, delta RGU,LSTM:0.059,-0.008\n",
      "Epoch 11. Time,GRU,LSTM: 5.752,6.537,7.054, Train loss,GRU,LSTM: 0.311,0.243,0.314, delta RGU,LSTM:0.067,-0.004\n",
      "Epoch 12. Time,GRU,LSTM: 5.753,6.532,7.056, Train loss,GRU,LSTM: 0.298,0.218,0.293, delta RGU,LSTM:0.081,0.005\n",
      "Epoch 13. Time,GRU,LSTM: 5.743,6.544,7.072, Train loss,GRU,LSTM: 0.291,0.192,0.271, delta RGU,LSTM:0.099,0.020\n",
      "Epoch 14. Time,GRU,LSTM: 5.747,6.540,7.068, Train loss,GRU,LSTM: 0.279,0.170,0.249, delta RGU,LSTM:0.109,0.030\n",
      "Epoch 15. Time,GRU,LSTM: 5.735,6.537,7.070, Train loss,GRU,LSTM: 0.271,0.153,0.226, delta RGU,LSTM:0.118,0.045\n",
      "Epoch 16. Time,GRU,LSTM: 5.744,6.554,7.075, Train loss,GRU,LSTM: 0.265,0.142,0.204, delta RGU,LSTM:0.123,0.061\n",
      "Epoch 17. Time,GRU,LSTM: 5.745,6.558,7.067, Train loss,GRU,LSTM: 0.248,0.130,0.181, delta RGU,LSTM:0.118,0.066\n",
      "Epoch 18. Time,GRU,LSTM: 5.750,6.533,7.055, Train loss,GRU,LSTM: 0.231,0.117,0.159, delta RGU,LSTM:0.114,0.071\n",
      "Epoch 19. Time,GRU,LSTM: 5.751,6.545,7.065, Train loss,GRU,LSTM: 0.227,0.106,0.139, delta RGU,LSTM:0.120,0.088\n",
      "Epoch 20. Time,GRU,LSTM: 5.754,6.550,7.067, Train loss,GRU,LSTM: 0.218,0.095,0.120, delta RGU,LSTM:0.123,0.099\n",
      "Epoch 21. Time,GRU,LSTM: 5.824,6.548,7.069, Train loss,GRU,LSTM: 0.209,0.086,0.102, delta RGU,LSTM:0.122,0.106\n",
      "Epoch 22. Time,GRU,LSTM: 5.749,6.540,7.072, Train loss,GRU,LSTM: 0.195,0.076,0.091, delta RGU,LSTM:0.120,0.104\n",
      "Epoch 23. Time,GRU,LSTM: 5.748,6.543,7.069, Train loss,GRU,LSTM: 0.189,0.068,0.083, delta RGU,LSTM:0.121,0.106\n",
      "Epoch 24. Time,GRU,LSTM: 5.745,6.541,7.069, Train loss,GRU,LSTM: 0.184,0.060,0.082, delta RGU,LSTM:0.125,0.103\n",
      "Epoch 25. Time,GRU,LSTM: 5.736,6.553,7.078, Train loss,GRU,LSTM: 0.178,0.054,0.061, delta RGU,LSTM:0.124,0.117\n",
      "Epoch 26. Time,GRU,LSTM: 5.748,6.555,7.073, Train loss,GRU,LSTM: 0.174,0.047,0.052, delta RGU,LSTM:0.127,0.122\n",
      "Epoch 27. Time,GRU,LSTM: 5.754,6.537,7.070, Train loss,GRU,LSTM: 0.164,0.040,0.044, delta RGU,LSTM:0.124,0.120\n",
      "Epoch 28. Time,GRU,LSTM: 5.749,6.540,7.068, Train loss,GRU,LSTM: 0.147,0.034,0.038, delta RGU,LSTM:0.113,0.109\n",
      "Epoch 29. Time,GRU,LSTM: 5.761,6.537,7.080, Train loss,GRU,LSTM: 0.151,0.030,0.034, delta RGU,LSTM:0.122,0.118\n",
      "Epoch 30. Time,GRU,LSTM: 5.749,6.544,7.043, Train loss,GRU,LSTM: 0.143,0.027,0.030, delta RGU,LSTM:0.116,0.113\n",
      "Epoch 31. Time,GRU,LSTM: 5.741,6.544,7.075, Train loss,GRU,LSTM: 0.137,0.025,0.027, delta RGU,LSTM:0.112,0.110\n",
      "Epoch 32. Time,GRU,LSTM: 5.755,6.546,7.068, Train loss,GRU,LSTM: 0.137,0.023,0.026, delta RGU,LSTM:0.114,0.111\n",
      "Epoch 33. Time,GRU,LSTM: 5.763,6.536,7.067, Train loss,GRU,LSTM: 0.127,0.022,0.024, delta RGU,LSTM:0.105,0.104\n",
      "Epoch 34. Time,GRU,LSTM: 5.749,6.542,7.073, Train loss,GRU,LSTM: 0.117,0.021,0.022, delta RGU,LSTM:0.096,0.095\n",
      "Epoch 35. Time,GRU,LSTM: 5.747,6.551,7.075, Train loss,GRU,LSTM: 0.119,0.021,0.021, delta RGU,LSTM:0.098,0.098\n",
      "Epoch 36. Time,GRU,LSTM: 5.746,6.539,7.064, Train loss,GRU,LSTM: 0.122,0.020,0.020, delta RGU,LSTM:0.102,0.102\n",
      "Epoch 37. Time,GRU,LSTM: 5.752,6.544,7.072, Train loss,GRU,LSTM: 0.116,0.020,0.019, delta RGU,LSTM:0.096,0.096\n",
      "Epoch 38. Time,GRU,LSTM: 5.752,6.549,7.068, Train loss,GRU,LSTM: 0.150,0.019,0.019, delta RGU,LSTM:0.131,0.132\n",
      "Epoch 39. Time,GRU,LSTM: 5.744,6.536,7.069, Train loss,GRU,LSTM: 0.154,0.019,0.018, delta RGU,LSTM:0.135,0.136\n",
      "Epoch 40. Time,GRU,LSTM: 5.750,6.536,7.059, Train loss,GRU,LSTM: 0.141,0.019,0.017, delta RGU,LSTM:0.123,0.124\n",
      "Epoch 41. Time,GRU,LSTM: 5.751,6.535,7.072, Train loss,GRU,LSTM: 0.128,0.018,0.017, delta RGU,LSTM:0.109,0.111\n",
      "Epoch 42. Time,GRU,LSTM: 5.761,6.534,7.071, Train loss,GRU,LSTM: 0.114,0.018,0.016, delta RGU,LSTM:0.096,0.098\n",
      "Epoch 43. Time,GRU,LSTM: 5.749,6.546,7.079, Train loss,GRU,LSTM: 0.100,0.018,0.016, delta RGU,LSTM:0.082,0.084\n",
      "Epoch 44. Time,GRU,LSTM: 5.745,6.556,7.073, Train loss,GRU,LSTM: 0.085,0.018,0.016, delta RGU,LSTM:0.067,0.069\n",
      "Epoch 45. Time,GRU,LSTM: 5.749,6.546,7.071, Train loss,GRU,LSTM: 0.073,0.017,0.015, delta RGU,LSTM:0.056,0.058\n",
      "Epoch 46. Time,GRU,LSTM: 5.741,6.538,7.067, Train loss,GRU,LSTM: 0.065,0.017,0.015, delta RGU,LSTM:0.048,0.050\n",
      "Epoch 47. Time,GRU,LSTM: 5.751,6.547,7.074, Train loss,GRU,LSTM: 0.054,0.017,0.015, delta RGU,LSTM:0.037,0.039\n",
      "Epoch 48. Time,GRU,LSTM: 5.745,6.552,7.064, Train loss,GRU,LSTM: 0.045,0.017,0.015, delta RGU,LSTM:0.028,0.030\n",
      "Epoch 49. Time,GRU,LSTM: 5.751,6.544,7.055, Train loss,GRU,LSTM: 0.035,0.017,0.014, delta RGU,LSTM:0.018,0.020\n",
      "Epoch 50. Time,GRU,LSTM: 5.749,6.550,7.068, Train loss,GRU,LSTM: 0.029,0.016,0.014, delta RGU,LSTM:0.013,0.015\n",
      "Epoch 51. Time,GRU,LSTM: 5.818,6.544,7.068, Train loss,GRU,LSTM: 0.025,0.016,0.014, delta RGU,LSTM:0.009,0.011\n",
      "Epoch 52. Time,GRU,LSTM: 5.742,6.535,7.065, Train loss,GRU,LSTM: 0.023,0.016,0.014, delta RGU,LSTM:0.006,0.009\n",
      "Epoch 53. Time,GRU,LSTM: 5.763,6.546,7.072, Train loss,GRU,LSTM: 0.021,0.016,0.014, delta RGU,LSTM:0.005,0.007\n",
      "Epoch 54. Time,GRU,LSTM: 5.757,6.549,7.062, Train loss,GRU,LSTM: 0.020,0.016,0.014, delta RGU,LSTM:0.004,0.007\n",
      "Epoch 55. Time,GRU,LSTM: 5.740,6.531,7.065, Train loss,GRU,LSTM: 0.019,0.016,0.013, delta RGU,LSTM:0.004,0.006\n",
      "Epoch 56. Time,GRU,LSTM: 5.748,6.533,7.070, Train loss,GRU,LSTM: 0.019,0.016,0.013, delta RGU,LSTM:0.003,0.005\n",
      "Epoch 57. Time,GRU,LSTM: 5.748,6.541,7.069, Train loss,GRU,LSTM: 0.018,0.016,0.013, delta RGU,LSTM:0.003,0.005\n",
      "Epoch 58. Time,GRU,LSTM: 5.752,6.543,7.061, Train loss,GRU,LSTM: 0.018,0.015,0.013, delta RGU,LSTM:0.002,0.005\n",
      "Epoch 59. Time,GRU,LSTM: 5.749,6.543,7.075, Train loss,GRU,LSTM: 0.017,0.015,0.013, delta RGU,LSTM:0.002,0.004\n",
      "Epoch 60. Time,GRU,LSTM: 5.756,6.546,7.074, Train loss,GRU,LSTM: 0.017,0.015,0.013, delta RGU,LSTM:0.002,0.004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-7d3d2dd19e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0moptimizerLSTM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0manswers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelLSTM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterionLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-0d26e75cb0a7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#         return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mgru_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgru_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mgru_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 526\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%debug\n",
    "count = 0\n",
    "\n",
    "for ep in range(500):\n",
    "    \n",
    "    # RNN section\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "    \n",
    "    for i in range(int(len(X_train) / bs)):\n",
    "        batch = X_train[i * bs:(i + 1) * bs]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = Y_train[i * bs:(i + 1) * bs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, states = model.forward(X_batch)\n",
    "        answers = answers.reshape(bs,2)\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "    end = time.time()\n",
    "        \n",
    "    # GRU section\n",
    "    startGRU = time.time()\n",
    "    train_lossGRU = 0.\n",
    "    train_passedGRU = 0\n",
    "    \n",
    "    for i in range(int(len(X_train) / bs)):\n",
    "        batch = X_train[i * bs:(i + 1) * bs]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = Y_train[i * bs:(i + 1) * bs]\n",
    "\n",
    "        optimizerGRU.zero_grad()\n",
    "        answers, states = modelGRU.forward(X_batch)\n",
    "        answers = answers.reshape(bs,2)\n",
    "        loss = criterionGRU(answers, Y_batch)\n",
    "        train_lossGRU += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizerGRU.step()\n",
    "        train_passedGRU += 1\n",
    "    endGRU = time.time()\n",
    "    \n",
    "    # LSTM section\n",
    "    startLSTM = time.time()\n",
    "    train_lossLSTM = 0.\n",
    "    train_passedLSTM = 0\n",
    "    \n",
    "    for i in range(int(len(X_train) / bs)):\n",
    "        batch = X_train[i * bs:(i + 1) * bs]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = Y_train[i * bs:(i + 1) * bs]\n",
    "\n",
    "        optimizerLSTM.zero_grad()\n",
    "        answers, states = modelLSTM.forward(X_batch)\n",
    "        answers = answers.reshape(bs,2)\n",
    "        loss = criterionLSTM(answers, Y_batch)\n",
    "        train_lossLSTM += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizerLSTM.step()\n",
    "        train_passedLSTM += 1\n",
    "    endLSTM = time.time()\n",
    "    \n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        count = 0\n",
    "        trloss = train_loss / train_passed\n",
    "        trlossGRU = train_lossGRU / train_passedGRU\n",
    "        trlossLSTM = train_lossLSTM / train_passedLSTM\n",
    "        print(\"Epoch {}. Time,GRU,LSTM: {:.3f},{:.3f},{:.3f}, Train loss,GRU,LSTM: {:.3f},{:.3f},{:.3f}, delta RGU,LSTM:{:.3f},{:.3f}\".format(ep, end - start, endGRU - startGRU, endLSTM - startLSTM, trloss, trlossGRU,trlossLSTM, trloss - trlossGRU,trloss - trlossLSTM))\n",
    "        #print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}, \".format(ep, end - start,  trloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test, RNN, GRU, LSTM: 0.6648743718592964 0.6648743718592964 0.6648743718592964\n"
     ]
    }
   ],
   "source": [
    "# check accuracy test\n",
    "count_ok, count_okGRU, count_okLSTM = 0,0,0\n",
    "count_not, count_notGRU, count_notLSTM = 0,0,0\n",
    "func_c = torch.nn.LogSoftmax()\n",
    "\n",
    "for i in range(int(len(X_test) / bs)):\n",
    "    batch = X_test[i * bs:(i + 1) * bs]\n",
    "    X_batch = batch[:, :-1]\n",
    "    Y_batch = Y_test[i * bs:(i + 1) * bs]\n",
    "\n",
    "    answers, states = model.forward(X_batch)\n",
    "    answersGRU, states = model.forward(X_batch)\n",
    "    answersLSTM, states = model.forward(X_batch)\n",
    "    \n",
    "    classes = func_c(answers)\n",
    "    classes = classes.argmax(dim=2)\n",
    "    classesGRU = func_c(answersGRU)\n",
    "    classesGRU = classesGRU.argmax(dim=2)\n",
    "    classesLSTM = func_c(answersLSTM)\n",
    "    classesLSTM = classesLSTM.argmax(dim=2)\n",
    "    \n",
    "    for j in range(bs):\n",
    "        if classes[j] == Y_batch[j]:\n",
    "            count_ok += 1\n",
    "        else:\n",
    "            count_not += 1\n",
    "            \n",
    "        if classesGRU[j] == Y_batch[j]:\n",
    "            count_okGRU += 1\n",
    "        else:\n",
    "            count_notGRU += 1\n",
    "            \n",
    "        if classesLSTM[j] == Y_batch[j]:\n",
    "            count_okLSTM += 1\n",
    "        else:\n",
    "            count_notLSTM += 1\n",
    "            \n",
    "print (\"Accuracy test, RNN, GRU, LSTM:\", count_ok/(count_ok + count_not), count_okGRU/(count_okGRU + count_notGRU), count_okLSTM/(count_okLSTM + count_notLSTM))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train, RNN, GRU, LSTM: 0.8967584480600751 0.8967584480600751 0.8967584480600751\n"
     ]
    }
   ],
   "source": [
    "# check accuracy train\n",
    "count_ok, count_okGRU, count_okLSTM = 0,0,0\n",
    "count_not, count_notGRU, count_notLSTM = 0,0,0\n",
    "func_c = torch.nn.LogSoftmax()\n",
    "\n",
    "for i in range(int(len(X_train) / bs)):\n",
    "    batch = X_train[i * bs:(i + 1) * bs]\n",
    "    X_batch = batch[:, :-1]\n",
    "    Y_batch = Y_train[i * bs:(i + 1) * bs]\n",
    "\n",
    "    answers, states = model.forward(X_batch)\n",
    "    answersGRU, states = model.forward(X_batch)\n",
    "    answersLSTM, states = model.forward(X_batch)\n",
    "    \n",
    "    classes = func_c(answers)\n",
    "    classes = classes.argmax(dim=2)\n",
    "    classesGRU = func_c(answersGRU)\n",
    "    classesGRU = classesGRU.argmax(dim=2)\n",
    "    classesLSTM = func_c(answersLSTM)\n",
    "    classesLSTM = classesLSTM.argmax(dim=2)\n",
    "    \n",
    "    for j in range(bs):\n",
    "        if classes[j] == Y_batch[j]:\n",
    "            count_ok += 1\n",
    "        else:\n",
    "            count_not += 1\n",
    "            \n",
    "        if classesGRU[j] == Y_batch[j]:\n",
    "            count_okGRU += 1\n",
    "        else:\n",
    "            count_notGRU += 1\n",
    "            \n",
    "        if classesLSTM[j] == Y_batch[j]:\n",
    "            count_okLSTM += 1\n",
    "        else:\n",
    "            count_notLSTM += 1\n",
    "            \n",
    "print (\"Accuracy train, RNN, GRU, LSTM:\", count_ok/(count_ok + count_not), count_okGRU/(count_okGRU + count_notGRU), count_okLSTM/(count_okLSTM + count_notLSTM))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
