{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneg = pd.read_csv('../onegin.txt', sep='\\n', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем стихи\n",
    "max_len = 0\n",
    "phrases = []\n",
    "for ind in range(len(oneg)):\n",
    "    line = oneg[0][ind]\n",
    "    if re.search(r'\\t', line):\n",
    "        # удалить ^\\t\\t\n",
    "        line = re.sub(r'\\t\\t', '', line)\n",
    "        # удалить …………\n",
    "        line = re.sub(r'…', '', line)\n",
    "        # удалить все после [d]\n",
    "        line = re.sub(r'\\[\\d*\\].*$', '', line)\n",
    "        # удалить все в квадратных скобках\n",
    "        line = re.sub(r'\\[.*\\]', '', line)\n",
    "        # удалить все анлгийские буквы\n",
    "        line = re.sub(r'[abcdefghijklmnopqrstuvwxyz]', '', line)\n",
    "        # удалить \\xa0\n",
    "        line = re.sub(r'\\xa0', ' ', line)\n",
    "              \n",
    "        if len(line) > 0:\n",
    "            phrases.append(line)\n",
    "            line_len = len(line)\n",
    "            if line_len > max_len:\n",
    "                max_len = line_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set(' абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max_len+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)\n",
    "X = X.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1453, 38])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    for j, w in enumerate(text[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 33, 22, 19, 31,  5, 25, 33, 30, 32,  6, 16, 19, 14, 33, 31, 18,  1,\n",
       "         17, 33,  9, 13,  3, 13, 18, 28, 17,  7,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev):\n",
    "        super(Network, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 50).to(self.dev)\n",
    "        self.gru = torch.nn.RNN(50, 128, num_layers = 3, nonlinearity = 'relu', batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR)).to(self.dev)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkGRU(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev):\n",
    "        super(NetworkGRU, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 50).to(self.dev)\n",
    "        self.gru = torch.nn.GRU(50, 128, num_layers = 3, batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR)).to(self.dev)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dev):\n",
    "        super(NetworkLSTM, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 50).to(self.dev)\n",
    "        self.gru = torch.nn.LSTM(50, 128, num_layers = 3, batch_first=True).to(self.dev)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR)).to(self.dev)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 38, 35])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(dev)\n",
    "model.forward(X[0:1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 38, 35])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGRU = NetworkGRU(dev)\n",
    "modelGRU.forward(X[0:1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 38, 35])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLSTM = NetworkLSTM(dev)\n",
    "modelLSTM.forward(X[0:1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(line):\n",
    "    sentence = [w for w in line]\n",
    "    #sentence = ['к', 'а', 'к', ' ', 'р', 'а', 'н', 'о',' ']\n",
    "    state = None\n",
    "    for i in range(MAX_LEN):\n",
    "        X = torch.Tensor([[CHAR_TO_INDEX[sentence[i]]]]).type(torch.long)\n",
    "        X = X.to(dev)\n",
    "        if i == 0:\n",
    "            result, state = model.forward(X)\n",
    "        else:\n",
    "            result, state = model.forward_state(X, state)\n",
    "        prediction = result[0, -1, :]\n",
    "        index_of_prediction = prediction.argmax()\n",
    "        if i >= len(sentence) - 1:\n",
    "            if index_of_prediction == 0:\n",
    "                break\n",
    "        sentence.append(INDEX_TO_CHAR[index_of_prediction])\n",
    "        \n",
    "    line = ''.join(sentence)\n",
    "    line = re.sub(r'none.*$', '', line)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_GRU(line):\n",
    "    sentence = [w for w in line]\n",
    "    #sentence = ['к', 'а', 'к', ' ', 'р', 'а', 'н', 'о',' ']\n",
    "    state = None\n",
    "    for i in range(MAX_LEN):\n",
    "        X = torch.Tensor([[CHAR_TO_INDEX[sentence[i]]]]).type(torch.long)\n",
    "        X = X.to(dev)\n",
    "        if i == 0:\n",
    "            result, state = modelGRU.forward(X)\n",
    "        else:\n",
    "            result, state = modelGRU.forward_state(X, state)\n",
    "        prediction = result[0, -1, :]\n",
    "        index_of_prediction = prediction.argmax()\n",
    "        if i >= len(sentence) - 1:\n",
    "            if index_of_prediction == 0:\n",
    "                break\n",
    "        sentence.append(INDEX_TO_CHAR[index_of_prediction])\n",
    "\n",
    "    line = ''.join(sentence)\n",
    "    line = re.sub(r'none.*$', '', line)\n",
    "    print(line)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_LSTM(line):\n",
    "    sentence = [w for w in line]\n",
    "    #sentence = ['к', 'а', 'к', ' ', 'р', 'а', 'н', 'о',' ']\n",
    "    state = None\n",
    "    for i in range(MAX_LEN):\n",
    "        X = torch.Tensor([[CHAR_TO_INDEX[sentence[i]]]]).type(torch.long)\n",
    "        X = X.to(dev)\n",
    "        if i == 0:\n",
    "            result, state = modelLSTM.forward(X)\n",
    "        else:\n",
    "            result, state = modelLSTM.forward_state(X, state)\n",
    "        prediction = result[0, -1, :]\n",
    "        index_of_prediction = prediction.argmax()\n",
    "        if i >= len(sentence) - 1:\n",
    "            if index_of_prediction == 0:\n",
    "                break\n",
    "        sentence.append(INDEX_TO_CHAR[index_of_prediction])\n",
    "        \n",
    "    line = ''.join(sentence)\n",
    "    line = re.sub(r'none.*$', '', line)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как раноалумонч  ьн\n"
     ]
    }
   ],
   "source": [
    "generate_sentence('как рано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как раноос \n"
     ]
    }
   ],
   "source": [
    "generate_sentence_GRU('как рано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как раноо  саси  ссттт ввееаааиоен \n"
     ]
    }
   ],
   "source": [
    "generate_sentence_LSTM('как рано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = .1\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lrate)\n",
    "\n",
    "criterionGRU = torch.nn.CrossEntropyLoss()\n",
    "optimizerGRU = torch.optim.SGD(modelGRU.parameters(), lr=lrate)\n",
    "\n",
    "criterionLSTM = torch.nn.CrossEntropyLoss()\n",
    "optimizerLSTM = torch.optim.SGD(modelLSTM.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.901,2.052,2.174, delta RGU,LSTM:-0.151,-0.273\n",
      "как рано а асал  с сет  соосер соол    сел  соо\n",
      "как рано    оооо ооооооо о   nonenonenonenone  ооооnonenonenonenone ооо\n",
      "как рано   none                                   \n",
      "Epoch 39. Time,GRU,LSTM: 0.170,0.190,0.200, Train loss,GRU,LSTM: 1.725,2.004,2.070, delta RGU,LSTM:-0.280,-0.345\n",
      "как рано а  пала с прора стсооса стое    пто  п\n",
      "как рано о  оооо ооооое noneонnonenonenonenonenone nonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано            оооооооооо    nonenonenonenonenone      nonenone\n",
      "Epoch 59. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.647,1.969,2.031, delta RGU,LSTM:-0.321,-0.384\n",
      "как рано а  сас  с пртлтвстррееааае аа   nonenonenoneс none\n",
      "как рано о  оооо ооооо nonenoneнnonenonenonenonenoneнnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано          ооооооооооо  nonenonenonenonenonenonenonenone  nonenonenonenonenonenone\n",
      "Epoch 79. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.603,1.924,2.005, delta RGU,LSTM:-0.320,-0.402\n",
      "как рано а  насайн пре тnonenoneоиооднаnonenonenone   ооnonenonenonenonenoneс\n",
      "как рано о  оо о о оолnoneоnoneоnoneоnonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано     оо  ооооооооооо nonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 99. Time,GRU,LSTM: 0.170,0.190,0.205, Train loss,GRU,LSTM: 1.564,1.846,1.987, delta RGU,LSTM:-0.282,-0.424\n",
      "как рано а  насн н псе тивасот пала ьвьнолаnoneн о\n",
      "как рано о  оо а н срллстсоееооаааоnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано     оо  ооооооооооо nonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 119. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.528,1.759,1.974, delta RGU,LSTM:-0.231,-0.446\n",
      "как рано а  насн с псе товтпое да оео  солвн  в\n",
      "как рано о  оола сссрттnonenonenoneроеоааnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано    оооо оооооо  оо nonenonenonenonenoneооооnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 139. Time,GRU,LSTM: 0.170,0.190,0.205, Train loss,GRU,LSTM: 1.498,1.719,1.962, delta RGU,LSTM:-0.221,-0.464\n",
      "как рано а  noneазн с псот ов пое анн нолтnone иыва ь\n",
      "как рано о  оола ссспттnonenonenoneрреоааnonenonenonenoneаnonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо оооооо  оо nonenonenonenonenoneооnoneоnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 159. Time,GRU,LSTM: 0.165,0.195,0.200, Train loss,GRU,LSTM: 1.456,1.692,1.951, delta RGU,LSTM:-0.236,-0.495\n",
      "как рано а оназн н пт noneиовесооселтартвнтньоnoneиао\n",
      "как рано о  вола сспполаnonenoneтроолnonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо ооооо   оо nonenonenoneооооnoneоnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 179. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.419,1.672,1.940, delta RGU,LSTM:-0.252,-0.521\n",
      "как рано о  noneазн снвсnoneтаавлеетnoneьnoneтаан nonenonenonenonenonenoneтив\n",
      "как рано о  ооса сспптттттттооеаааыnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо ооооо   оо nonenonenoneооооnoneоnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 199. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.383,1.652,1.929, delta RGU,LSTM:-0.269,-0.546\n",
      "как рано а  назн с псе аавтнре д таеие невамн  \n",
      "как рано о  ооса ссппсттттттооеаааоnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо о ооо   онооnonenoneоооооnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 219. Time,GRU,LSTM: 0.160,0.195,0.200, Train loss,GRU,LSTM: 1.352,1.635,1.916, delta RGU,LSTM:-0.283,-0.564\n",
      "как рано о  сазн снвстмдавтеетвnoneе ье   оnonenoneс твс\n",
      "как рано о  ооса ссппсстттттооетооооnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо о ооо   о оаnonenoneоооооаnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 239. Time,GRU,LSTM: 0.165,0.190,0.200, Train loss,GRU,LSTM: 1.323,1.620,1.901, delta RGU,LSTM:-0.297,-0.578\n",
      "как рано от сазн сн noneомдавтевмтне не  ньыйво вс\n",
      "как рано о  ооса ссппссттдттооетооооnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оооо о оое   оноnonenonenonenoneооаоnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 259. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.309,1.605,1.883, delta RGU,LSTM:-0.296,-0.574\n",
      "как рано ал сази сньвомдлвта ег  еое в онсти пе\n",
      "как рано о  оаса сспсстттдттоетоооооnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оо о о оое о оноnonenonenonenonenoneоnonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 279. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.261,1.590,1.862, delta RGU,LSTM:-0.329,-0.601\n",
      "как рано ал сази сньвомдтnoneваnoneегnonenoneаnoneит noneдnonenonenonenonenoneаnone\n",
      "как рано о  паса сспсрлтлпттоееааооеоnonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оо о о оол о оnoneаnonenonenoneоnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 299. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.221,1.577,1.840, delta RGU,LSTM:-0.356,-0.619\n",
      "как рано ат сазн внввомдав ояейnone  нснтнnonenonenoneоекав\n",
      "как рано о  паса ссссрлтлсттттеааояоnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оо о   оо  онаааnonenonenoneоnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 319. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.193,1.565,1.821, delta RGU,LSTM:-0.373,-0.628\n",
      "как рано ал сазн рньвомдаваекегnonenonenoneолтnonenoneоnonenonenoneткnonenone\n",
      "как рано о  паса ссссрлтлстееееааояиnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  оо о   не  нннееаnonenonenoneоааnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 339. Time,GRU,LSTM: 0.180,0.190,0.205, Train loss,GRU,LSTM: 1.158,1.553,1.804, delta RGU,LSTM:-0.395,-0.646\n",
      "как рано аласазг рньвотдомаегяг евnonenoneноnoneоржоnonenonenoneг\n",
      "как рано о  паса ссссрлтлдттетеаооояnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о   оло   неенолnoneнноnonenonenonenonenonenonenoneоnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 359. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.109,1.539,1.788, delta RGU,LSTM:-0.430,-0.678\n",
      "как рано аласазо рнь о дйnoneаактнврдnonenoneтаnoneыеяа nonenoneт\n",
      "как рано о  паса ссссрлтлдтееееаооояnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о   оло   ннннолннноаааnonenoneооаnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 379. Time,GRU,LSTM: 0.170,0.190,0.200, Train loss,GRU,LSTM: 1.088,1.525,1.771, delta RGU,LSTM:-0.437,-0.684\n",
      "как рано ат сазг сндмомдовтоnoneег ннсрвnoneтnoneноик дnone\n",
      "как рано о  паса ссссолтлдтееевnoneаооnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о   оло   ннллолннноаааnonenoneооаnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 399. Time,GRU,LSTM: 0.170,0.190,0.205, Train loss,GRU,LSTM: 1.036,1.513,1.744, delta RGU,LSTM:-0.477,-0.708\n",
      "как рано атасазг рндльтаомаехеноnoneв нннрьйnonenoneнаая\n",
      "как рано о  паса ссссолтлстееевиаояьnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  ноло ннслоло ноараnonenonenonenoneоnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 419. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 1.024,1.499,1.722, delta RGU,LSTM:-0.475,-0.698\n",
      "как рано аласазо снь о дйрло пгир еястротаnoneгть \n",
      "как рано о  пасе ссссолтрстееевиаояnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  соло нсссрлолторееаайnoneаnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 439. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.984,1.489,1.707, delta RGU,LSTM:-0.505,-0.722\n",
      "как рано аласазо рнь о дмnoneаактгтруnoneмноеоаеж на \n",
      "как рано о  пазе ссссолллвтееевиоояnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола нтсррро ноенооойнотnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 459. Time,GRU,LSTM: 0.165,0.195,0.200, Train loss,GRU,LSTM: 0.941,1.475,1.692, delta RGU,LSTM:-0.535,-0.751\n",
      "как рано атасазг мзп ьмаороерн еnoneтнчйдонгnonenoneок о\n",
      "как рано о  пазе снссолллвтаятйnoneооnonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стсррра трораоойноойnonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 479. Time,GRU,LSTM: 0.165,0.190,0.210, Train loss,GRU,LSTM: 0.915,1.465,1.681, delta RGU,LSTM:-0.550,-0.766\n",
      "как рано аласазг снь оnoneдортыnonenoneдnoneакнеnonenonenoneаnoneтио nonenone\n",
      "как рано о  нази снссе алвтаетйдnonenoneяоnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стсррра тоороооннотnonenonenonenonenonenoneыnonenonenonenone\n",
      "Epoch 499. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.898,1.454,1.673, delta RGU,LSTM:-0.556,-0.775\n",
      "как рано аласази рнь о дреаакт трудтnoneиnoneрыеnoneне н\n",
      "как рано о  наз  снссе авnoneтеетйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стстрталтоараоейьыnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 519. Time,GRU,LSTM: 0.165,0.190,0.210, Train loss,GRU,LSTM: 0.841,1.453,1.666, delta RGU,LSTM:-0.612,-0.825\n",
      "как рано атасазг мндльваороаюе оя  м нтпттрдеиа\n",
      "как рано о  назе внссе анвееяяйдnonenoneотnonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стпррралтеооооониийnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 539. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.814,1.434,1.658, delta RGU,LSTM:-0.619,-0.843\n",
      "как рано алосозо сньюоверптоnonenoneманае nonenonenonenone ьнтирnone\n",
      "как рано о  наз  снссе авnoneтеетйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стпррлалнеооооениойnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 559. Time,GRU,LSTM: 0.170,0.190,0.200, Train loss,GRU,LSTM: 0.771,1.419,1.650, delta RGU,LSTM:-0.648,-0.879\n",
      "как рано аласазо езь о дмnoneпоямихо noneестн noneдсрнтв\n",
      "как рано о  назе внссе анвееятnoneдnonenoneоттnonenonenonenonenonenonenonenoneьnone\n",
      "как рано о  сола стпррлалнеооооениойnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 579. Time,GRU,LSTM: 0.170,0.190,0.205, Train loss,GRU,LSTM: 0.714,1.407,1.645, delta RGU,LSTM:-0.693,-0.931\n",
      "как рано аласози езь овдрий яnoneбеаnone ыс noneосл тнло\n",
      "как рано о  наз  внссе авnoneееякйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стпсрлалттаоеоойnoneыыnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 599. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.741,1.395,1.637, delta RGU,LSTM:-0.654,-0.895\n",
      "как рано ой гузи вн вотчиу увёлрин б яж ивымрв \n",
      "как рано о  наз  внссе авnoneееякйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стпсрлалттаоеоайnoneыыnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 619. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.687,1.389,1.630, delta RGU,LSTM:-0.702,-0.944\n",
      "как рано аласозо взьвойдйnoneеояяю оnone лгтн воnoneеуоя\n",
      "как рано о  наз  внссе авnoneееккйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  сола стпсрралсеооеоонинnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 639. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.671,1.375,1.623, delta RGU,LSTM:-0.704,-0.952\n",
      "как рано акасузг вздтоnoneдудеярвмnonenoneшnoneйнвуяnonenoneкnonenoneое\n",
      "как рано о  наз  внссе авnoneееккйдnonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поса стпсортттеооетиеееnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 659. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.628,1.367,1.616, delta RGU,LSTM:-0.739,-0.988\n",
      "как рано акасузг вздтиедидыяррслние  ьяяаохтслс\n",
      "как рано о  називвнссе алааоякnonenonenoneьnonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поса стпсортттеооетиеееnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 679. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.612,1.351,1.607, delta RGU,LSTM:-0.739,-0.995\n",
      "как рано аласазо взьво дмnoneоовяювулnoneлдnoneт еnoneиnoneьиnone\n",
      "как рано о  наз  внссе авnoneеекnonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поса стссорттсеоеетаеееnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 699. Time,GRU,LSTM: 0.165,0.195,0.205, Train loss,GRU,LSTM: 0.549,1.337,1.603, delta RGU,LSTM:-0.788,-1.054\n",
      "как рано алисозо взь отдмсеоямзnoneа тй noneнарnoneдрnoneмв\n",
      "как рано о  нази внссе алвсокnonenonenonenoneьятйnonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поса стссорттттоеетоееееnonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 719. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.496,1.325,1.595, delta RGU,LSTM:-0.829,-1.099\n",
      "как рано аласузо взьво дкnoneоояямблнnoneмдnoneньоао noneо \n",
      "как рано о  назо внссе арвсокnonenonenonenoneоотйnonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поса стссррттсеоееаеее   nonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 739. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.546,1.316,1.592, delta RGU,LSTM:-0.769,-1.045\n",
      "как рано алимозч сзьвит исе бузалнкимачьтnoneоий none\n",
      "как рано о  наз  снссе авnoneтектйдnonenonenonenoneнnonenonenoneеnonenonenonenonenonenone\n",
      "как рано о  поса стссррттсеоееаеее    nonenonenonenonenonenonenonenonenone\n",
      "Epoch 759. Time,GRU,LSTM: 0.170,0.185,0.205, Train loss,GRU,LSTM: 0.568,1.313,1.581, delta RGU,LSTM:-0.745,-1.014\n",
      "как рано аласозг сзьвомдоевобnoneд улжnoneльnoneаиж дnoneяс\n",
      "как рано ор назо вндве орвееооннндотnonenonenonenoneыоойnonenonenone\n",
      "как рано о  поса стссрлттсеоееааае    nonenonenonenonenonenonenonenonenone\n",
      "Epoch 779. Time,GRU,LSTM: 0.165,0.195,0.200, Train loss,GRU,LSTM: 0.600,1.288,1.574, delta RGU,LSTM:-0.688,-0.974\n",
      "как рано аласозг сзьвовдоевобядловнеретоагсомдц\n",
      "как рано ор назо сндве орвтеоонnoneндооnonenonenonenonenonenoneейnonenonenone\n",
      "как рано о  поси стссрлттвеоееаааее   nonenonenonenonenonenonenonenonenone\n",
      "Epoch 799. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.350,1.278,1.562, delta RGU,LSTM:-0.928,-1.212\n",
      "как рано алимозч сзь ит нсе бкзесик даагмнтахор\n",
      "как рано о  назо снссе арвтеттйnonenoneооnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  поси стссрлттвеоееаааее   nonenonenonenonenonenonenonenonenone\n",
      "Epoch 819. Time,GRU,LSTM: 0.180,0.185,0.205, Train loss,GRU,LSTM: 0.502,1.271,1.557, delta RGU,LSTM:-0.770,-1.055\n",
      "как рано аламонч сзьве нис мхядла яоиотиессснмь\n",
      "как рано о  назо снссе арвтеттйnonenoneооnonenonenoneьnonenonenonenonenonenonenonenone\n",
      "как рано о  поси стссрлттвеоееаааее   nonenonenonenonenonenonenonenonenone\n",
      "Epoch 839. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.271,1.253,1.554, delta RGU,LSTM:-0.981,-1.282\n",
      "как рано алимозч сзьвит ас  безаслкодеб тнуагnoneв\n",
      "как рано ор назо сндве онвтеоонннnonenoneоннnonenoneыыnonenonenonenoneы\n",
      "как рано о  поси стссрлттвеоееаааее   nonenonenonenonenonenonenonenonenone\n",
      "Epoch 859. Time,GRU,LSTM: 0.165,0.190,0.200, Train loss,GRU,LSTM: 0.254,1.247,1.540, delta RGU,LSTM:-0.993,-1.286\n",
      "как рано алимозч сзьвит нс  бузасакимачнмnone оnone none\n",
      "как рано о  назо сбссе арвтеттйnonenoneооnonenonenonenonenonenonenonenonenonenonenonenone\n",
      "как рано о  паси стссрл  пеоееаеитор nonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 879. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.264,1.228,1.534, delta RGU,LSTM:-0.964,-1.270\n",
      "как рано алимозч сзь итансх бкзе ут оаулмлщохнд\n",
      "как рано ор назо сндвесонвтеоонтнnoneооннnonenonenoneыnonenonenonenoneы\n",
      "как рано о  паси стссрс  пеоееаеитортnonenonenonenonenonenonenonenoneыnone\n",
      "Epoch 899. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.246,1.218,1.524, delta RGU,LSTM:-0.973,-1.278\n",
      "как рано алимозч сзьвитанс  безаnoneьвимаблмnoneгока \n",
      "как рано ор назо сбдое онвтеойnonenonenonenonenoneоннnonenonenonenonenonenonenonenoneо\n",
      "как рано о  паси стссрс  пеоееаеитортnonenonenonenonenonenonenonenoneыnone\n",
      "Epoch 919. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.237,1.215,1.515, delta RGU,LSTM:-0.978,-1.278\n",
      "как рано алумонч тзьбомоитымнодnoneтньл уйе noneукесм\n",
      "как рано ор назо сбдоедонвтеойnonenoneмnoneыnoneннnonenonenonenonenonenonenonenoneо\n",
      "как рано о  паси стссрс  пеоееаеитортnonenonenonenonenonenonenonenoneыnone\n",
      "Epoch 939. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.233,1.188,1.508, delta RGU,LSTM:-0.955,-1.275\n",
      "как рано алумонч тзьбомоитымнодnoneтнnoneл уке noneувас \n",
      "как рано ор назо сбдое онвтеойnonenonenonenonenoneоннnonenonenonenonenonenonenonenoneо\n",
      "как рано о  саси стссттт веоетааииен nonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 959. Time,GRU,LSTM: 0.165,0.195,0.210, Train loss,GRU,LSTM: 0.228,1.187,1.506, delta RGU,LSTM:-0.959,-1.277\n",
      "как рано алумонч тзьбомоитымнодатнnoneл уке ру ео \n",
      "как рано о  noneазо сбссnoneлонвтеттnonenoneнnonenonenonenonenoneьnonenonenonenonenonenonenonenone\n",
      "как рано о  саси стссттт пеоетааииортnonenonenonenonenonenonenonenoneьnone\n",
      "Epoch 979. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.226,1.166,1.501, delta RGU,LSTM:-0.941,-1.275\n",
      "как рано алумонч тзьбомоитымнодатнол уке русесм\n",
      "как рано ол noneазо сбувемонвтотьтnoneйnoneыойnonenoneеnonenonenonenoneкnonenone\n",
      "как рано о  саси стссттт пеоетааииортnonenonenonenonenonenonenonenoneьnone\n",
      "Epoch 999. Time,GRU,LSTM: 0.165,0.190,0.205, Train loss,GRU,LSTM: 0.223,1.158,1.489, delta RGU,LSTM:-0.934,-1.265\n",
      "как рано алумонч тзьномоитымнодnoneтnoneрс ойн nonenoneикот\n",
      "как рано ос noneазо сбтналонвтеоаяnonenonenonenonenonenoneнnonenonenonenonenonenonenonenonenone\n",
      "как рано о  саси стссттт веоееааииен nonenonenonenonenonenonenonenonenonenone\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for ep in range(1000):\n",
    "    \n",
    "    # RNN section\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "    \n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, _ = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "    end = time.time()\n",
    "        \n",
    "    # GRU section\n",
    "    startGRU = time.time()\n",
    "    train_lossGRU = 0.\n",
    "    train_passedGRU = 0\n",
    "    \n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizerGRU.zero_grad()\n",
    "        answers, _ = modelGRU.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterionGRU(answers, Y_batch)\n",
    "        train_lossGRU += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizerGRU.step()\n",
    "        train_passedGRU += 1\n",
    "    endGRU = time.time()\n",
    "    \n",
    "    # LSTM section\n",
    "    startLSTM = time.time()\n",
    "    train_lossLSTM = 0.\n",
    "    train_passedLSTM = 0\n",
    "    \n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizerLSTM.zero_grad()\n",
    "        answers, _ = modelLSTM.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterionLSTM(answers, Y_batch)\n",
    "        train_lossLSTM += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizerLSTM.step()\n",
    "        train_passedLSTM += 1\n",
    "    endLSTM = time.time()\n",
    "    \n",
    "    count += 1\n",
    "    if count == 20:\n",
    "        count = 0\n",
    "        trloss = train_loss / train_passed\n",
    "        trlossGRU = train_lossGRU / train_passedGRU\n",
    "        trlossLSTM = train_lossLSTM / train_passedLSTM\n",
    "        print(\"Epoch {}. Time,GRU,LSTM: {:.3f},{:.3f},{:.3f}, Train loss,GRU,LSTM: {:.3f},{:.3f},{:.3f}, delta RGU,LSTM:{:.3f},{:.3f}\".format(ep, end - start, endGRU - startGRU, endLSTM - startLSTM, trloss, trlossGRU,trlossLSTM, trloss - trlossGRU,trloss - trlossLSTM))\n",
    "        generate_sentence('как рано ')\n",
    "        generate_sentence_GRU('как рано ')        \n",
    "        generate_sentence_LSTM('как рано ')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence2(line):\n",
    "    generate_sentence(line)\n",
    "    generate_sentence_GRU(line)\n",
    "    generate_sentence_LSTM(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как раноалумонч  ьн\n",
      "как раноос \n",
      "как раноо  саси  ссттт ввееаааиоен \n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('как рано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привет чувакеа есесагс ирлсмняе ояи о\n",
      "привет чувакооеыт навсл вн \n",
      "привет чувакоолольсесо    ьнаян\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('привет чувак')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " нам от разне не всегда по моды\n",
      " соседа своей \n",
      " от полна столине стола\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ана призлостя\n",
      "атель не в поставил свет\n",
      "а столи в серенный сердень\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('а')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "схоеодйро евог лоа тм\n",
      "схоеодйд наие  тв\n",
      "схооотт ьои м посолттаиа\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('схо')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "каретаалуйи\n",
      "каретаосе   мьлв\n",
      "каретао и    с ссссепееее ннт\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('карета')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "зах он\n",
      "зой поставил своей\n",
      "зоре полителья сердень\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('з')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "так думал молодой ам\n",
      "так думал молодой о  \n",
      "так думал молодой ол не  л иолиньй пнона\n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('так думал молодой ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с новым годом евежый ортнв\n",
      "с новым годом епавый иорав пгелл\n",
      "с новым годом ооамо  иолел он  \n"
     ]
    }
   ],
   "source": [
    "generate_sentence2('с новым годом ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
